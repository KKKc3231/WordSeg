2021-05-05 22:42:17,259:INFO: device: cuda:0
2021-05-05 22:42:17,259:INFO: --------Process Done!--------
2021-05-05 22:42:17,946:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2021-05-05 22:42:17,946:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2021-05-05 22:42:17,946:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2021-05-05 22:42:17,946:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2021-05-05 22:42:17,946:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2021-05-05 22:42:17,946:INFO: loading file None
2021-05-05 22:42:17,947:INFO: loading file None
2021-05-05 22:42:17,947:INFO: loading file None
2021-05-05 22:43:16,248:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2021-05-05 22:43:16,249:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2021-05-05 22:43:16,249:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2021-05-05 22:43:16,249:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2021-05-05 22:43:16,249:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2021-05-05 22:43:16,249:INFO: loading file None
2021-05-05 22:43:16,249:INFO: loading file None
2021-05-05 22:43:16,249:INFO: loading file None
2021-05-05 22:43:22,868:INFO: --------Dataset Build!--------
2021-05-05 22:43:22,868:INFO: --------Get Dataloader!--------
2021-05-05 22:43:22,868:INFO: loading configuration file pretrained_bert_models/bert-base-chinese/config.json
2021-05-05 22:43:22,868:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "lstm_dropout_prob": 0.5,
  "lstm_embedding_size": 768,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2021-05-05 22:43:22,869:INFO: loading weights file pretrained_bert_models/bert-base-chinese/pytorch_model.bin
2021-05-05 22:43:25,282:INFO: Weights of BertSeg not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
2021-05-05 22:43:25,282:INFO: Weights from pretrained model not used in BertSeg: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
2021-05-05 22:43:26,576:INFO: --------Start Training!--------
2021-05-05 22:53:18,561:INFO: Epoch: 1, train loss: 0.2172552114491732
2021-05-05 22:53:57,777:INFO: Epoch: 1, dev loss: 0.07991764489852357, f1 score: 0.9692591345045828
2021-05-05 22:53:57,777:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 22:53:59,392:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 22:53:59,392:INFO: --------Save best model!--------
2021-05-05 23:03:53,732:INFO: Epoch: 2, train loss: 0.06704713948037996
2021-05-05 23:04:32,959:INFO: Epoch: 2, dev loss: 0.06286309366914793, f1 score: 0.9760385224788224
2021-05-05 23:04:32,960:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 23:04:34,558:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 23:04:34,559:INFO: --------Save best model!--------
2021-05-05 23:14:28,972:INFO: Epoch: 3, train loss: 0.04246368540242693
2021-05-05 23:15:08,303:INFO: Epoch: 3, dev loss: 0.06090099900175119, f1 score: 0.9784028171007928
2021-05-05 23:15:08,303:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 23:15:09,826:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 23:15:09,827:INFO: --------Save best model!--------
2021-05-05 23:25:05,178:INFO: Epoch: 4, train loss: 0.029243253953161904
2021-05-05 23:25:44,484:INFO: Epoch: 4, dev loss: 0.061072357365446805, f1 score: 0.9800614175597582
2021-05-05 23:25:44,484:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 23:25:46,039:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 23:25:46,039:INFO: --------Save best model!--------
2021-05-05 23:35:41,469:INFO: Epoch: 5, train loss: 0.020856379915528855
2021-05-05 23:36:20,688:INFO: Epoch: 5, dev loss: 0.0630036621068939, f1 score: 0.9811618136015691
2021-05-05 23:36:20,689:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 23:36:22,274:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 23:36:22,274:INFO: --------Save best model!--------
2021-05-05 23:46:18,707:INFO: Epoch: 6, train loss: 0.01489104959739641
2021-05-05 23:46:57,997:INFO: Epoch: 6, dev loss: 0.06710928459583557, f1 score: 0.9817940140455039
2021-05-05 23:46:57,997:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 23:46:59,482:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 23:46:59,482:INFO: --------Save best model!--------
2021-05-05 23:56:54,880:INFO: Epoch: 7, train loss: 0.011390722950280867
2021-05-05 23:57:34,335:INFO: Epoch: 7, dev loss: 0.07227427916182023, f1 score: 0.9819218103895299
2021-05-05 23:57:34,336:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-05 23:57:35,983:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-05 23:57:35,983:INFO: --------Save best model!--------
2021-05-06 00:07:31,275:INFO: Epoch: 8, train loss: 0.008832573852655378
2021-05-06 00:08:10,489:INFO: Epoch: 8, dev loss: 0.07471876172139673, f1 score: 0.9826497444844964
2021-05-06 00:08:10,490:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-06 00:08:12,028:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-06 00:08:12,028:INFO: --------Save best model!--------
2021-05-06 00:18:08,253:INFO: Epoch: 9, train loss: 0.006860616607661893
2021-05-06 00:18:47,619:INFO: Epoch: 9, dev loss: 0.07437668991170768, f1 score: 0.982768243955596
2021-05-06 00:18:47,620:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-06 00:18:49,348:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-06 00:18:49,348:INFO: --------Save best model!--------
2021-05-06 00:28:44,490:INFO: Epoch: 10, train loss: 0.005440775295586373
2021-05-06 00:29:23,722:INFO: Epoch: 10, dev loss: 0.07724132416263955, f1 score: 0.9832051594601182
2021-05-06 00:29:23,723:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-06 00:29:25,423:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-06 00:29:25,423:INFO: --------Save best model!--------
2021-05-06 00:39:19,736:INFO: Epoch: 11, train loss: 0.004410989877498671
2021-05-06 00:39:59,039:INFO: Epoch: 11, dev loss: 0.0771891390405699, f1 score: 0.9828851505858579
2021-05-06 00:49:55,324:INFO: Epoch: 12, train loss: 0.003412385728168537
2021-05-06 00:50:34,492:INFO: Epoch: 12, dev loss: 0.08345873417154052, f1 score: 0.9832157237969941
2021-05-06 00:50:34,493:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-06 00:50:36,157:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-06 00:50:36,157:INFO: --------Save best model!--------
2021-05-06 01:00:32,726:INFO: Epoch: 13, train loss: 0.002806535337865529
2021-05-06 01:01:11,904:INFO: Epoch: 13, dev loss: 0.08957279076078066, f1 score: 0.9830080194346055
2021-05-06 01:11:07,564:INFO: Epoch: 14, train loss: 0.0024360612003058264
2021-05-06 01:11:46,863:INFO: Epoch: 14, dev loss: 0.08944420929428673, f1 score: 0.9832898334300818
2021-05-06 01:11:46,863:INFO: Configuration saved in /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-06 01:11:48,410:INFO: Model weights saved in /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-06 01:11:48,410:INFO: --------Save best model!--------
2021-05-06 01:11:48,410:INFO: Best val f1: 0.9832898334300818
2021-05-06 01:11:48,410:INFO: Training Finished!
2021-05-06 01:11:48,522:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2021-05-06 01:11:48,522:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2021-05-06 01:11:48,522:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2021-05-06 01:11:48,522:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2021-05-06 01:11:48,522:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2021-05-06 01:11:48,522:INFO: loading file None
2021-05-06 01:11:48,522:INFO: loading file None
2021-05-06 01:11:48,522:INFO: loading file None
2021-05-06 01:11:54,871:INFO: --------Dataset Build!--------
2021-05-06 01:11:54,871:INFO: --------Get Data-loader!--------
2021-05-06 01:11:54,871:INFO: loading configuration file /home/xiaheming/workspace/wordseg/experiments/config.json
2021-05-06 01:11:54,871:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "lstm_dropout_prob": 0.5,
  "lstm_embedding_size": 768,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2021-05-06 01:11:54,871:INFO: loading weights file /home/xiaheming/workspace/wordseg/experiments/pytorch_model.bin
2021-05-06 01:11:57,186:INFO: --------Load model from /home/xiaheming/workspace/wordseg/experiments/--------
2021-05-06 01:12:27,240:INFO: --------Bad Cases reserved !--------
2021-05-06 01:12:27,408:INFO: test loss: 0.28474249138529406, f1 score: 0.9647653748906428, precision: 0.9681907206051192, recall: 0.9613641806773003
